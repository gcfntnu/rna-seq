#-*- mode: snakemake -*-
"""

Snakemake rules for aligning rna-seq fastq files to genome using the
STAR aligner.

This is a single pass alignment with known reference and gene model. The
output is coordinate sorted bam files with marked duplicates and the
companion index (.bai) file.


Dependencies
------------
STAR, https://github.com/alexdobin/STAR
SAMBAMBA,

"""

import os
from os.path import join

extra_conf_fn = srcdir('star.config')
if os.path.exists(extra_conf_fn):
    with open(extra_conf_fn) as fh:
        c  = yaml.load(fh) or {}
        update_config2(config, c)

STAR_INTERIM = join(ALIGN_INTERIM, 'star')
STAR_PROCESSED = join(ALIGN_PROCESSED, 'star')
REF = config['align']['reference']

def star_input_params(wildcards):
    """Multiple fastq files per sample workaround.

    STAR uses comma separated input when defining a read with mutiple fastq files.
    A comma separated string is not a valid input file in snakemake.
    A work around in snakemake is to build the comma separated input string as a params.fastq
    
    """
    R1 = get_processed_fastq_R1(wildcards)
    if config['samples'][wildcards.sample]['paired_end']: 
        R2 = get_processed_fastq_R2(wildcards)
    else:
        R2 = []
    R1 = ','.join(sorted(set(R1)))
    R2 = ','.join(sorted(set(R2)))
    input_string = ' '.join([R1, R2])
    return input_string

rule star_genome_index:
    input: 
        genome = join(ENSEMBL_EXT, 'fasta', 'genome.fa'),
        gtf = join(ENSEMBL_EXT, 'genes', 'genes.gtf')
    output:
         join(ENSEMBL_EXT, 'star', 'SA')
    params:
        index_dir =  join(ENSEMBL_EXT, 'star'),
        readlength = '100'
    threads:
        24
    log:
        join(ENSEMBL_EXT, 'logs', 'STAR.index.log')
    singularity:
        'docker://gcfntnu/ensembl:0.1' 
    shell:
        'STAR '
        '--runThreadN {threads} '
        '--runMode genomeGenerate '
        '--genomeDir {params.index_dir} '
        '--genomeFastaFiles {input.genome} '
        '--sjdbGTFfile {input.gtf} '
        '--sjdbOverhang {params.readlength} '
        '&& mv Log.out {log}'

rule star_firstpass:
    input:
        genome = join(ENSEMBL_EXT, 'star', 'SA'),
        fastq = get_processed_fastq_R1
    params:
        prefix = lambda wildcards, output: output[0].split('firstpass.SJ.out.tab')[0],
        read_length = '100',
        fastq = star_input_params,
        genome_dir = join(ENSEMBL_EXT, 'star')
    output:
        sj = temp(join(STAR_INTERIM, '{sample}.firstpass.SJ.out.tab'))
    threads:
        48
    log:
        'logs/{sample}.1pass.Log.final.out'
    conda:
        'envs/align.yaml'
    shell: 
        'STAR '
        '--runThreadN {threads} '
        '--genomeDir {params.genome_dir} '
        '--genomeLoad LoadAndKeep ' 
        '--readFilesCommand zcat '
        '--outSAMtype None '
        '--outFileNamePrefix {params.prefix} '
        '--readFilesIn {params.fastq} '
        '&& cp {params.prefix}Log.final.out {log} '
        
rule star_clean_memory_1pass:
    params:
        rules.star_firstpass.params.genome_dir
    output:
        temp(touch('.star.mem.1pass.cleaned'))
    conda:
        'envs/align.yaml'         
    shell:
        'STAR '
        '--genomeDir {params} '
        '--genomeLoad Remove '
        '--outFileNamePrefix /tmp/foo '
        '|| echo "NO 1pass SHARED MEMORY" '

if config['align']['star']['twopass']:
    rule star_align:
        input:
            genome = join(ENSEMBL_EXT, 'star', 'SA'),
            fastq = get_processed_fastq_R1,
            sj = expand(rules.star_firstpass.output, sample=SAMPLES)
        params:
            fastq = star_input_params,
            prefix = lambda wildcards, output: output.bam.split('Aligned.sortedByCoord.out.bam')[0],
            genome_dir = lambda wildcards, input: os.path.dirname(input.genome)
        output:
            bam = temp(join(STAR_INTERIM, 'STAR', '{sample}.Aligned.sortedByCoord.out.bam'))
        threads:
            48
        log:
            'logs/{sample}.Log.final.out'
        conda:
            'envs/align.yaml'
        shell: 
            'STAR '
            '--runThreadN {threads} '
            '--genomeDir {params.genome_dir} '
            '--readFilesCommand zcat '
            '--outSAMtype BAM SortedByCoordinate '
            '--outFilterType BySJout '
            '--sjdbFileChrStartEnd {input.sj '
            '--outMultimapperOrder Random '
            '--outSAMmultNmax 20 '
            '--outSAMstrandField intronMotif '
            '--outReadsUnmapped Fastx '
            '--outFileNamePrefix {params.prefix} '
            '--readFilesIn {params.fastq} '
            '&& cp {params.prefix}Log.final.out {log} '
else:
    rule star_align:
        input:
            genome = join(ENSEMBL_EXT, 'star', 'SA'),
            fastq = get_processed_fastq_R1
        params:
            fastq = star_input_params,
            prefix = lambda wildcards, output: output.bam.split('Aligned.sortedByCoord.out.bam')[0],
            genome_dir = lambda wildcards, input : os.path.dirname(input.genome)
        output:
            bam = temp(join(STAR_INTERIM, 'STAR', '{sample}.Aligned.sortedByCoord.out.bam'))
        threads:
            48
        log:
            'logs/{sample}.Log.final.out'
        conda:
            'envs/align.yaml'    
        shell: 
            'STAR '
            '--runThreadN {threads} '
            '--genomeDir {params.genome_dir} '
            '--genomeLoad LoadAndKeep '
            '--readFilesCommand zcat '
            '--limitBAMsortRAM 20000000000 ' 
            '--outSAMtype BAM SortedByCoordinate '
            '--outFilterType BySJout '
            '--outMultimapperOrder Random '
            '--outSAMmultNmax 20 '
            '--outSAMstrandField intronMotif '
            '--outReadsUnmapped Fastx '
            '--outFileNamePrefix {params.prefix} '
            '--readFilesIn {params.fastq} '
            '&& cp {params.prefix}Log.final.out {log} '

rule star_mark_duplicates:
    input:
        bam = rules.star_align.output.bam,
    output:
        bam = join(STAR_INTERIM, '{sample}.sorted.bam')
    threads:
        4
    shell:
        'sambamba markdup -t {threads} {input.bam} {output.bam} '

rule star_index_bam:
    input:
        rules.star_mark_duplicates.output.bam
    output:
        bai = join(STAR_INTERIM, '{sample}.sorted.bam.bai')
    threads:
        4
    shell:
        'sambamba index -t {threads} {input} '
           
rule star_namesort_bam:
    input:
       rules.star_mark_duplicates.output.bam,
       rules.star_index_bam.output
    output:
        join(STAR_INTERIM, '{sample}.namesorted.bam')
    threads:
        8
    shell:
        'sambamba sort -N -p -m 24G -t {threads} -o {output} {input}'
